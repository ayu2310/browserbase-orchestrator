"""Autonomous Browserbase orchestrator built on MCP + OpenAI."""
from __future__ import annotations

import asyncio
import json
import textwrap
import uuid
from dataclasses import dataclass, field
from typing import Any, Awaitable, Callable, Dict, List, Optional, Tuple

from openai import OpenAI

from config import OPENAI_API_KEY, OPENAI_MODEL
from database import get_flow_state, init_database, save_flow_state
from mcp_client import MCPClient


ALLOWED_TOOLS = [
    "browserbase_session_create",
    "browserbase_session_close",
    "browserbase_stagehand_navigate",
    "browserbase_stagehand_observe",
    "browserbase_stagehand_act",
    "browserbase_stagehand_extract",
    "browserbase_stagehand_screenshot",
    "browserbase_stagehand_get_url",
    "browserbase_list_cached_actions",
]


@dataclass
class PlannerDecision:
    """Structured plan generated by the LLM."""

    status: str
    tool: Optional[str] = None
    arguments: Dict[str, Any] = field(default_factory=dict)
    response: str = ""
    reasoning: str = ""


class Planner:
    """LLM-based planner that decides which MCP tool to call next."""

    def __init__(self) -> None:
        if not OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY is required for orchestrator planner")
        self.client = OpenAI(api_key=OPENAI_API_KEY)

    async def decide(
        self,
        task_prompt: str,
        history: List[Dict[str, Any]],
        state_snapshot: str,
        screenshot: Optional[str] = None,
    ) -> PlannerDecision:
        """Call GPT-4o to choose the next MCP tool invocation."""

        screenshot_context = ""
        if screenshot:
            screenshot_context = f"\n\nCURRENT PAGE SCREENSHOT (base64 image):\nYou can see the current state of the page. Use this to understand what's visible and make informed decisions about what actions to take."
        
        prompt = textwrap.dedent(
            f"""
            You are an autonomous browser automation agent. Your task: {task_prompt}
            
            Current state: {state_snapshot}
            Recent actions: {json.dumps(history[-3:], indent=2) if history else "None"}
            {screenshot_context}
            
            CRITICAL WORKFLOW FOR COMPLEX TASKS:
            1. Always start with browserbase_session_create (if no session)
            2. Navigate to the target URL
            3. Take a screenshot to see the page
            4. Use browserbase_stagehand_act for ALL interactions (clicks, typing, scrolling, form filling)
            5. Use browserbase_stagehand_extract ONLY for reading/extracting data (not for interactions)
            6. Take screenshots after important actions to verify results
            7. Close session when done
            
            AVAILABLE TOOLS (flowState is automatically handled - don't include it):
            
            1. browserbase_session_create
               When: Start of task (only if no session exists)
               How: {{}} (empty arguments)
            
            2. browserbase_stagehand_navigate
               When: Go to a website or change pages
               How: {{"url": "https://example.com"}}
               Note: This sets the startingUrl but does NOT create actions. Use act for navigation interactions.
            
            3. browserbase_stagehand_screenshot
               When: You need to see what's on the page
               How: {{}} (empty arguments)
               Note: Use this frequently to understand page state. Take screenshots after important actions.
            
            4. browserbase_stagehand_observe
               When: You need to find a SPECIFIC element that's hard to describe (use sparingly, max 2-3 times per task)
               How: {{"instruction": "Find the login button", "returnAction": true}}
               Note: Only use if natural language actions fail. Prefer browserbase_stagehand_act with natural language.
            
            5. browserbase_stagehand_act ‚≠ê USE THIS FOR ALL INTERACTIONS
               When: ANY interaction with the page (click, type, scroll, fill, select, etc.)
               How: {{"action": "Natural language description of what to do"}}
               Examples:
                 - Click button: {{"action": "Click the 'Sign In' button"}}
                 - Type text: {{"action": "Type 'username123' in the email input field"}}
                 - Fill form: {{"action": "Fill the login form with email 'user@example.com' and password 'pass123'"}}
                 - Scroll: {{"action": "Scroll down to see more products"}}
                 - Select: {{"action": "Select 'United States' from the country dropdown"}}
                 - Wait: {{"action": "Wait for the page to load"}}
               IMPORTANT: This is the ONLY tool that creates actions in flowState. Use it for ALL user interactions.
            
            6. browserbase_stagehand_extract
               When: Extract structured data from the page (reading only, no interactions)
               How: {{"instruction": "Extract the top 5 products with names and descriptions"}}
               Note: Use this to get data. More reliable than observe for reading content.
            
            7. browserbase_stagehand_get_url
               When: Check current URL
               How: {{}} (empty arguments)
            
            8. browserbase_session_close
               When: Task is complete
               How: {{}} (empty arguments)
               Then: Immediately return status "finish"
            
            WORKFLOW:
            1. If no session: create session
            2. Navigate to target URL
            3. Take screenshot to see the page
            4. Based on screenshot, decide actions:
               - If you need to find a button: observe (sparingly)
               - If you need to interact: act with natural language
               - If you need data: extract
            5. When done: close session, then finish
            
            IMPORTANT:
            - Use screenshots to understand the page before acting
            - Prefer natural language actions over observe
            - Extract data directly - don't observe first
            - Close session when complete, then return finish status
            
            Respond with JSON:
            {{
                "status": "call_tool" | "finish",
                "tool": "<tool name>",
                "arguments": {{...}},
                "reasoning": "<why you chose this action>",
                "response": "<summary when finish>"
            }}
            """
        ).strip()

        def _call_llm() -> str:
            messages = [
                {
                    "role": "system",
                    "content": "You are a precise automation planner. Follow the tool usage rules strictly. CRITICAL RULES:\n1. You MUST include ALL required parameters in the 'arguments' object for each tool call.\n2. For browserbase_stagehand_extract, you MUST include 'instruction' parameter (string).\n3. For browserbase_stagehand_navigate, you MUST include 'url' parameter (string).\n4. For browserbase_stagehand_observe, you MUST include 'instruction' parameter (string).\n5. For browserbase_stagehand_act, you MUST include EITHER 'action' (string) OR 'observation' (object).\n6. flowState is AUTOMATICALLY handled by the system - you do NOT need to include it in arguments.\n7. flowState enables deterministic re-executions - the system automatically manages it for session continuity and replay.\n8. Use screenshots to see the page and make informed decisions.\n9. Avoid unnecessary observe calls (max 2-3 per task).\n10. Always close sessions when finishing.\n11. Always output valid JSON.",
                },
            ]
            
            # Add screenshot to user message if available
            user_content = [{"type": "text", "text": prompt}]
            if screenshot:
                # Screenshot is base64, add as image
                user_content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": screenshot if screenshot.startswith("data:") else f"data:image/png;base64,{screenshot}"
                    }
                })
            
            messages.append({"role": "user", "content": user_content})
            
            response = self.client.chat.completions.create(
                model=OPENAI_MODEL,
                temperature=0.2,
                response_format={"type": "json_object"},
                messages=messages,
            )
            return response.choices[0].message.content or "{}"

        raw = await asyncio.to_thread(_call_llm)
        try:
            data = json.loads(raw)
        except json.JSONDecodeError as exc:
            raise ValueError(f"Planner returned invalid JSON: {raw}") from exc

        status = data.get("status", "").lower()
        decision = PlannerDecision(
            status=status,
            tool=data.get("tool"),
            arguments=data.get("arguments") or {},
            response=data.get("response", ""),
            reasoning=data.get("reasoning", ""),
        )

        if decision.status == "call_tool" and decision.tool not in ALLOWED_TOOLS:
            raise ValueError(f"Planner selected unsupported tool: {decision.tool}")

        return decision


@dataclass
class OrchestratorResult:
    """Structured orchestrator output."""

    cache_key: str
    mode: str
    summary: str
    steps: List[Dict[str, Any]]
    flow_state: Optional[Dict[str, Any]]


class OrchestratorAgent:
    """Coordinates the MCP client + LLM planner into an autonomous agent."""

    def __init__(
        self,
        task_prompt: str,
        cache_key: Optional[str] = None,
        mode: str = "autonomous",
        max_steps: int = 30,
        on_update: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None,
    ) -> None:
        init_database()
        self.task_prompt = task_prompt.strip()
        self.mode = mode
        self.max_steps = max_steps
        self.cache_key = cache_key or f"flow-{uuid.uuid4().hex}"
        self.history: List[Dict[str, Any]] = []
        self.planner = Planner()
        self.mcp_client = MCPClient(cache_key=self.cache_key)
        self.on_update = on_update
        self._hydrate_existing_state()

    def _hydrate_existing_state(self) -> None:
        existing = get_flow_state(self.cache_key)
        if existing:
            self.mcp_client.hydrate(existing["flow_state"])

    async def run(self) -> OrchestratorResult:
        """Run autonomous orchestration."""
        if self.mode == "replay":
            return await self._run_replay()

        await self._ensure_session()
        summary = "Maximum step count reached without finish signal."

        # Take initial screenshot after navigation
        last_screenshot = None
        
        for step in range(1, self.max_steps + 1):
            # Get LLM decision (pass screenshot if available)
            decision = await self.planner.decide(
                self.task_prompt,
                self.history,
                self.mcp_client.describe_state(),
                screenshot=last_screenshot,
            )

            # Stream LLM reasoning
            if self.on_update:
                await self.on_update({
                    "type": "reasoning",
                    "step": step,
                    "reasoning": decision.reasoning,
                    "tool": decision.tool,
                    "status": decision.status,
                })

            if decision.status == "finish":
                summary = decision.response or "Task marked as complete."
                
                # Preserve flowState before closing session
                preserved_flow_state = self.mcp_client.flow_state
                
                # Close session before finishing
                try:
                    await self.mcp_client.invoke("browserbase_session_close", {})
                    # Restore preserved flowState (closing might clear it)
                    if preserved_flow_state and not self.mcp_client.flow_state:
                        self.mcp_client.flow_state = preserved_flow_state
                    self._persist_flow_state()
                    if self.on_update:
                        await self.on_update({
                            "type": "session_closed",
                            "message": "Browser session closed",
                        })
                except Exception as e:
                    # Session close is best effort
                    pass
                
                if self.on_update:
                    await self.on_update({
                        "type": "complete",
                        "summary": summary,
                    })
                break

            if decision.status != "call_tool" or not decision.tool:
                summary = decision.response or "Planner could not decide on a tool; stopping."
                if self.on_update:
                    await self.on_update({
                        "type": "error",
                        "message": summary,
                    })
                break
            
            # Handle tool errors gracefully - retry with different approach
            max_retries = 2
            retry_count = 0
            result = None
            tool_error = None
            
            while retry_count <= max_retries:
                try:
                    # Execute tool
                    result = await self._invoke_tool(decision.tool, decision.arguments)
                    tool_error = None
                    break
                except Exception as e:
                    tool_error = str(e)
                    retry_count += 1
                    if retry_count <= max_retries:
                        # If tool fails, try to recover
                        if "not found" in tool_error.lower() or "error" in tool_error.lower():
                            # Tool doesn't exist or failed - try alternative approach
                            if decision.tool == "browserbase_stagehand_screenshot":
                                # Screenshot failed, continue without it
                                result = {"message": "Screenshot unavailable, continuing"}
                                break
                            elif decision.tool == "browserbase_stagehand_observe":
                                # Observe failed, suggest using natural language act instead
                                if self.on_update:
                                    await self.on_update({
                                        "type": "reasoning",
                                        "step": step,
                                        "reasoning": f"Observe failed: {tool_error}. Will try natural language action instead.",
                                        "tool": decision.tool,
                                        "status": "retry",
                                    })
                                # Don't retry observe, let LLM decide next step
                                result = {"message": f"Observe failed: {tool_error}"}
                                break
                            else:
                                # Other tool failed, retry once
                                await asyncio.sleep(1)  # Brief pause before retry
                                continue
                        else:
                            # Unknown error, don't retry
                            raise
                    else:
                        # Max retries reached
                        raise
            
            if tool_error and not result:
                # Tool failed after retries
                if self.on_update:
                    await self.on_update({
                        "type": "error",
                        "message": f"Tool {decision.tool} failed after retries: {tool_error}",
                    })
                # Continue to next step instead of breaking
                result = {"message": f"Tool failed: {tool_error}"}
            
            # If session was closed, next decision should be finish
            if decision.tool == "browserbase_session_close":
                # Wait for next decision which should be finish
                next_decision = await self.planner.decide(
                    self.task_prompt,
                    self.history,
                    self.mcp_client.describe_state(),
                )
                if next_decision.status == "finish":
                    summary = next_decision.response or "Task completed."
                    if self.on_update:
                        await self.on_update({
                            "type": "complete",
                            "summary": summary,
                        })
                    break
            
            # Take screenshot after each action (skip if tool was already screenshot)
            screenshot_data = None
            if decision.tool != "browserbase_stagehand_screenshot":
                try:
                    screenshot_result = await self.mcp_client.invoke("browserbase_stagehand_screenshot", {})
                    screenshot_data = self._extract_screenshot(screenshot_result)
                    if screenshot_data:
                        last_screenshot = screenshot_data  # Store for next decision
                    # Update flowState after screenshot
                    self._persist_flow_state()
                except Exception as e:
                    # Screenshot is optional, continue if it fails
                    pass
            else:
                # If screenshot was the tool, extract it from result
                screenshot_data = self._extract_screenshot(result)
                if screenshot_data:
                    last_screenshot = screenshot_data  # Store for next decision

            self._record_step(step, decision, result)
            
            # Stream step update with flowState and screenshot
            if self.on_update:
                # Ensure flowState is included (should always exist now due to minimal creation)
                flow_state_to_send = self.mcp_client.flow_state
                if not flow_state_to_send:
                    # Fallback: create minimal if somehow missing
                    flow_state_to_send = {"cacheKey": self.cache_key}
                
                await self.on_update({
                    "type": "step",
                    "step": step,
                    "tool": decision.tool,
                    "result": self._summarize_result(result),
                    "flow_state": flow_state_to_send,
                    "screenshot": screenshot_data,
                })

        # Ensure session is closed
        try:
            if self.mcp_client.has_active_session:
                await self.mcp_client.invoke("browserbase_session_close", {})
                self._persist_flow_state()
        except Exception:
            pass
        
        # Final cleanup - ensure session is closed
        try:
            if self.mcp_client.has_active_session:
                await self.mcp_client.invoke("browserbase_session_close", {})
                self._persist_flow_state()
                if self.on_update:
                    await self.on_update({
                        "type": "session_closed",
                        "message": "Browser session closed",
                    })
        except Exception:
            pass
        
        # Preserve flowState before closing (in case close clears it)
        final_flow_state = self.mcp_client.flow_state
        
        await self.mcp_client.close()
        return OrchestratorResult(
            cache_key=self.cache_key,
            mode=self.mode,
            summary=summary,
            steps=self.history,
            flow_state=final_flow_state,  # Use preserved flowState
        )

    async def _run_replay(self) -> OrchestratorResult:
        """Replay previously stored flowState."""
        stored = get_flow_state(self.cache_key)
        if not stored:
            raise ValueError(
                f"No stored flowState found for cache_key '{self.cache_key}'. "
                "Run an autonomous session first."
            )

        self.mcp_client.hydrate(stored["flow_state"])
        result = await self.mcp_client.invoke(
            "browserbase_stagehand_act",
            {"replayState": stored["flow_state"]},
        )
        summary = self._summarize_result(result)
        
        # Close session after replay
        try:
            await self.mcp_client.invoke("browserbase_session_close", {})
        except Exception:
            pass
        
        await self.mcp_client.close()
        return OrchestratorResult(
            cache_key=self.cache_key,
            mode="replay",
            summary=summary or "Replay executed.",
            steps=[
                {
                    "step": 1,
                    "tool": "browserbase_stagehand_act",
                    "arguments": {"replayState": "stored"},
                    "result": summary,
                    "success": True,
                }
            ],
            flow_state=stored["flow_state"],
        )

    async def _ensure_session(self) -> None:
        """Ensure a Browserbase session is created."""
        if self.mcp_client.has_active_session:
            return
        await self.mcp_client.invoke(
            "browserbase_session_create",
            {"flowState": {"cacheKey": self.cache_key}},
        )
        self._persist_flow_state()

    async def _invoke_tool(
        self, tool: str, arguments: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Invoke MCP tool and persist resulting flowState."""
        arguments = arguments or {}
        result = await self.mcp_client.invoke(tool, arguments)
        self._persist_flow_state()
        return result

    def _persist_flow_state(self) -> None:
        if self.mcp_client.flow_state:
            save_flow_state(
                cache_key=self.cache_key,
                prompt=self.task_prompt,
                flow_state=self.mcp_client.flow_state,
            )

    def _record_step(
        self,
        step_number: int,
        decision: PlannerDecision,
        result: Dict[str, Any],
    ) -> None:
        summary = self._summarize_result(result)
        self.history.append(
            {
                "step": step_number,
                "tool": decision.tool,
                "arguments": decision.arguments,
                "result": summary,
                "reasoning": decision.reasoning,
            }
        )

    def _summarize_result(self, result: Dict[str, Any]) -> str:
        """Return a human-friendly summary of the MCP response."""
        if not result:
            return "Empty response"

        text_chunks: List[str] = []
        if "message" in result and isinstance(result["message"], str):
            text_chunks.append(result["message"])

        content = result.get("content")
        if isinstance(content, list):
            for item in content:
                if isinstance(item, dict):
                    if item.get("type") == "text":
                        text_chunks.append(str(item.get("text", "")))
                    elif item.get("type") == "json":
                        try:
                            text_chunks.append(json.dumps(item.get("json"), ensure_ascii=False))
                        except (TypeError, ValueError):
                            pass

        if not text_chunks:
            text_chunks.append(json.dumps(result, ensure_ascii=False)[:500])

        summary = " ".join(chunk.strip() for chunk in text_chunks if chunk).strip()
        return summary[:800]

    def _extract_screenshot(self, result: Dict[str, Any]) -> Optional[str]:
        """Extract screenshot data from MCP response."""
        if not result:
            return None
        
        # Try to find screenshot in various response formats
        content = result.get("content")
        if isinstance(content, list):
            for item in content:
                if isinstance(item, dict):
                    # Check for image data (MCP format: type="image", data="base64...")
                    if item.get("type") == "image":
                        # Check various possible fields
                        data = item.get("data") or item.get("image") or item.get("screenshot")
                        if data:
                            # Ensure it's base64 format (starts with data:image or is base64 string)
                            if isinstance(data, str):
                                if data.startswith("data:image"):
                                    return data
                                elif len(data) > 100:  # Likely base64 image data
                                    return data
                    # Check for base64 encoded image in other fields
                    if "image" in item or "screenshot" in item:
                        data = item.get("data") or item.get("image") or item.get("screenshot")
                        if data and isinstance(data, str) and len(data) > 100:
                            return data
        
        # Check raw response
        raw = result.get("raw", {})
        if isinstance(raw, dict):
            if "screenshot" in raw:
                screenshot = raw["screenshot"]
                if isinstance(screenshot, str) and len(screenshot) > 100:
                    return screenshot
            if "image" in raw:
                image = raw["image"]
                if isinstance(image, str) and len(image) > 100:
                    return image
        
        # Check message field (sometimes screenshot is in message text)
        message = result.get("message", "")
        if isinstance(message, str) and ("screenshot" in message.lower() or "image" in message.lower()):
            # Try to extract base64 from message
            import re
            base64_match = re.search(r'data:image/[^;]+;base64,([A-Za-z0-9+/=]+)', message)
            if base64_match:
                return f"data:image/png;base64,{base64_match.group(1)}"
        
        return None


__all__ = ["OrchestratorAgent", "OrchestratorResult"]


